<!doctype html>
<!--[if lt IE 7 ]> <html class="ie ie6 ie-lt10 ie-lt9 ie-lt8 ie-lt7 no-js" lang="en"> <![endif]-->
<!--[if IE 7 ]> <html class="ie ie7 ie-lt10 ie-lt9 ie-lt8 no-js" lang="en"> <![endif]-->
<!--[if IE 8 ]> <html class="ie ie8 ie-lt10 ie-lt9 no-js" lang="en"> <![endif]-->
<!--[if IE 9 ]> <html class="ie ie9 ie-lt10 no-js" lang="en"> <![endif]-->
<!--[if gt IE 9]><!--><html class="no-js" lang="en"><!--<![endif]-->

<html>

	<head>
		<meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

    <title>Diogo Carbonera Luvizon</title>
    <meta name="author" content="Diogo Carbonera Luvizon" />
    <meta name="description" content="Luvizon's web page" />
    <meta name="Copyright" content="Diogo Carbonera Luvizon" />

		<meta name="viewport" content="width=device-width, initial-scale=1" />

		<!--[if lte IE 8]><script src="assets/js/ie/html5shiv.js"></script><![endif]-->
		<link rel="stylesheet" href="assets/css/main.css" />
		<!--[if lte IE 8]><link rel="stylesheet" href="assets/css/ie8.css" /><![endif]-->

    <!-- Twitter: see https://dev.twitter.com/docs/cards/types/summary-card for details -->
    <meta name="twitter:card" content="">
    <meta name="twitter:site" content="">
    <meta name="twitter:title" content="">
    <meta name="twitter:description" content="">
    <meta name="twitter:url" content="">
    <!-- Facebook (and some others) use the Open Graph protocol: see http://ogp.me/ for details -->
    <meta property="og:title" content="" />
    <meta property="og:description" content="" />
    <meta property="og:url" content="" />
    <meta property="og:image" content="" />

	</head>

	<body id="top">

		<!-- Header -->
    <header id="header">
      <div class="inner">
        <a href="#" class="image avatar"><img src="images/photo.jpeg" alt="" /></a>
        <h1>Diogo C Luvizon</h1>
        <p>Postdoctoral Researcher at <b>MPI-INF</b><br>
          Researcher at <b>VIA Research Center</b><br>
          Ex AI Researcher at <b>Samsung</b>
        </p>
        

        <nav></br>
          <a href="#vitae">Vitae</a></br>
          <a href="#news">News</a></br>
          <a href="#publications">Publications</a></br>
          <!--<a href="https://scholar.google.com/citations?user=VZ1Q5v4AAAAJ&hl=fr&oi=ao" target="_blank">Google scholar</a></br>-->
          <!-- <a href="#code">Source Code</a></br> -->
          <!-- <a href="#teaching">Teaching</a></br> -->
          <a href="#contact">Contact</a>
        </nav>

      </div>
    </header>

		<!-- Main -->
    <div id="main">

      <!-- Vitae -->
      <section id="vitae">
        <header class="major">
          <h2>About me</h2>
        </header>

        <div class="8u 12u$(xsmall) work-item">
          <p class="justified">
          I received my PhD in Computer Vision and Machine Learning from the <a target="_blank" href="https://www.cyu.fr/" class="icon">CY Cergy Paris University</a> (Université de Cergy-Pontoise), France, in April 2019.
          My thesis was developed at the <a target="_blank" href="https://www.etis-lab.fr/" class="icon">ETIS Lab</a> under the supervision of <a target="_blank" href="https://davidpicard.github.io/" class="icon">David Picard</a>
          and <a target="_blank" href="https://www.ibisc.univ-evry.fr/~htabia/"
          class="icon">Hedi Tabia</a> and supported by the Brazilian
          National Council for Scientific and Technological Development (CNPq).  I
          received my Master's degree in <b>Applied Computing</b> (Graphics and Computer
          Vision) from the Federal University of Technology - Paraná (UTFPR),
          Brazil, in 2015, and my Bachelor's degree in <b>Electronics Engineering</b>
          from the UTFPR, in 2011.  I have worked
          with <b>computer vision applied to embedded and real-time systems</b> (2011-2015), and with computer vision algorithms for <b>on-device applications</b> at <a target="_blank" href="https://research.samsung.com/srbr">Samsung</a> (2019-2021).
          Since 2021, I am a Postdoctoral Researcher at the <a target="_blank" href="https://www.mpi-inf.mpg.de">Max-Planck-Institut für Informatik</a>, under the supervision of <a target="_blank" href="https://people.mpi-inf.mpg.de/~theobalt/">Christian Theobalt</a>, and a Research Member of the <b>Saarbrücken Research Center for Visual Computing, Interaction and Artificial Intelligence</b> (<a href="https://www.via-center.science/">VIA Research Center</a>, a partnership between MPI-INF and <b>Google</b>). See my <a target="_blank" href="https://people.mpi-inf.mpg.de/~dluvizon">official web page</a> at MPI-INF for more information.
          </p>
        </div>

        <h2>Research Interests</h2>
        <div class="8u 12u$(xsmall) work-item">
          <p class="justified">
            My research interests are mainly focused on solving complex problems in the areas of Computer Vision, Computer Graphics, and Deep Learning, specially applied to <b>modeling humans in their environment</b>. I am passionate about working on challenging research problems that have a real impact on people's lives.
          </p>
        </div>

        <!--<ul class="actions">-->
          <!--<li><a target="_blank" href="data/cv.pdf" class="button">Link to my CV (PDF)</a></li>-->
        <!--</ul>-->
      </section>

      <!-- News -->
      <section id="news">
        <h2>News</h2>
        <p class="8u justified">
          <ul class="news">
            <li>One paper accepted to <b>3DV 2024</b>! [<a target="_blank" href="https://4dqv.mpi-inf.mpg.de/Ev2Hands/">Ev2Hands</a>] </li>
            <li>Patent granted by the <b>USPTO</b> in 2023 (while on Samsung)! [<a target="_blank" href="https://image-ppubs.uspto.gov/dirsearch-public/print/downloadPdf/11704778">PDF</a>]</li>
            <li>One paper accepted to Pattern Recognition and one paper accepted to <b>CVPR 2023</b>! [<a target="_blank" href="https://arxiv.org/abs/2009.01998">SSP-Net</a>]  [<a target="_blank" href="https://people.mpi-inf.mpg.de/~jianwang/projects/sceneego/">SceneEgo</a>]  </li>
            <li>Four papers accepted in between 2022-2023: <a target="_blank" href="https://link.springer.com/article/10.1007/s11263-021-01570-9">IJCV</a>, <a target="_blank" href="https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Estimating_Egocentric_3D_Human_Pose_in_the_Wild_With_External_CVPR_2022_paper.pdf">CVPR</a>, <a target="_blank" href="https://arxiv.org/pdf/2210.01692.pdf">VMV</a>, and <a target="_blank" href="https://arxiv.org/pdf/2301.05175.pdf">EUROGRAPHICS</a>.
            <li>Paper accepted to <b>BMVC 2021</b>! [<a target="_blank" href="https://arxiv.org/abs/2110.09380">arXiv</a>]  [<a target="_blank" href="https://cyclempi.github.io/">Project page</a>]  </li>
            <li>Sep. 2021: I am moving to <a href="https://www.mpi-inf.mpg.de/departments/visual-computing-and-artificial-intelligence">MPI-INF</a> as a postdoctoral researcher!
            <li>Our WACV'21 paper will be presented at CVPR'21 Workshop "Learning to Generate 3D Shapes and Scenes" [<a target="_blank" href="https://learn3dg.github.io/">workshop</a>]</li>
            <li>Paper accepted to <b>ICASSP 2021</b>! [<a target="_blank" href="https://arxiv.org/abs/2102.11771">arXiv</a>]</li>
            <li>Paper accepted to <b>WACV 2021</b>! [<a target="_blank" href="https://arxiv.org/abs/2011.13317">arXiv</a>]</li>
            <li>Paper accepted to <b>ICIP 2020</b>! [<a target="_blank" href="https://arxiv.org/abs/2010.02680">arXiv</a>]</li>
            <li>Paper accepted to <b class=showpopup title="24.314 impact factor">TPAMI 2020</b>! [<a target="_blank" href="https://ieeexplore.ieee.org/abstract/document/9007695">IEEE Xplore</a>]</li>
            <li>Paper accepted to <b>CVPR 2018</b>! [<a target="_blank" href="https://openaccess.thecvf.com/content_cvpr_2018/html/Luvizon_2D3D_Pose_Estimation_CVPR_2018_paper.html">CVF open access</a>]</li>
          </ul>
        </p>

      </section>

      <!-- Publications -->
      <section id="publications">
        <h2>Publications</h2>
        <p>Please see my <a target="_blank" href="https://people.mpi-inf.mpg.de/~dluvizon/">Web Page @ MPI-INF</a> and my <a target="_blank" href="https://scholar.google.com/citations?user=VZ1Q5v4AAAAJ&hl=fr&oi=ao" class="icon">Google Scholar</a> for recent publications.</p>
        <!--<div class="row">-->
        <div>

          <article class="8u 12u$(xsmall) work-item">
            <h3 class=justified>Adaptive Multiplane Image Generation from a Single Internet Picture</h3>
            <a href="https://arxiv.org/abs/2011.13317" target="_blank" class="image fit thumb">
              <video controls autoplay loop muted><source src="images/wacv2021.webm" type="video/webm">Your browser does not support HTML video.
              </video>
            </a>
            <p class=justified><b>Diogo C. Luvizon, Gustavo Sutter P. Carvalho, Andreza A. dos Santos, Jhonatas S. Conceicão, Jose L. Flores-Campana, Luis G. L. Decker, Marcos R. Souza, Helio Pedrini, Antonio Joia, Otávio A. B. Penatti</b>. <i>The IEEE Winter Conference on Applications of Computer Vision (WACV)</i>, 2021.</p>
            <p>
              [<a target="_blank" href="https://openaccess.thecvf.com/content/WACV2021/html/Luvizon_Adaptive_Multiplane_Image_Generation_From_a_Single_Internet_Picture_WACV_2021_paper.html">the CVF</a>]
              [<a target="_blank" href="https://arxiv.org/pdf/2011.13317.pdf">arXiv</a>]
              [<a target="_blank" href="https://www.youtube.com/watch?v=b9hiU0I-Lz4">video</a>]
            </p>
          </article>

          <article class="8u 12u$(xsmall) work-item">
            <h3 class=justified>Parallax Motion Effect Generation Through Instance Segmentation And Depth Estimation</h3>
            <a href="https://ieeexplore.ieee.org/abstract/document/9191168" target="_blank" class="image fit thumb"><img src="images/icip2020.svg" alt="" /></a>
            <p class=justified><b>Allan Pinto, Manuel A. Córdova, Luis G. L. Decker, Jose L. Flores-Campana, Marcos R. Souza, Andreza A. dos Santos, Jhonatas S. Conceição, Henrique F. Gagliardi, Diogo C. Luvizon, Ricardo da S. Torres, and Helio Pedrini</b>. <i>The IEEE International Conference on Image Processing (ICIP)</i>, 2020.</p>
            <p>
              [<a target="_blank" href="https://arxiv.org/pdf/2010.02680.pdf">pdf</a>]
              [<a target="_blank" href="https://allansp84.github.io/motion-parallax/">project page</a>]
              [<a target="_blank" href="data/icip2020.txt">bibtex</a>]
            </p>
          </article>

          <article class="8u 12u$(xsmall) work-item">
            <h3 class=justified>Multi-task Deep Learning for Real-Time 3D Human Pose Estimation and Action Recognition</h3>
            <a href="https://ieeexplore.ieee.org/abstract/document/9007695" target="_blank" class="image fit thumb"><img src="images/tpami2020.jpg" alt="" /></a>
            <p class=justified><b>Diogo Luvizon, David Picard, Hedi Tabia</b>. <i>The IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</i>, 2020.</p>
            <p>
              [<a target="_blank" href="https://ieeexplore.ieee.org/abstract/document/9007695">ieeexplorer</a>]
              [<a target="_blank" href="https://arxiv.org/pdf/1912.08077.pdf">pdf</a>]
              [<a target="_blank" href="https://github.com/dluvizon/deephar">code</a>]
              [<a target="_blank" href="data/tpami2020.txt">bibtex</a>]
            </p>
          </article>

          <article class="8u 12u$(xsmall) work-item">
            <h3>Human pose regression by combining indirect part detection and contextual information</h3>
            <a href="https://arxiv.org/pdf/1710.02322" target="_blank" class="image fit thumb"><img src="images/cag2019.png" alt="" /></a>
            <p><b>Diogo C. Luvizon, Hedi Tabia, David Picard</b>. <i>Computers & Graphics</i>, 2019.</p>
            <p>
              [<a target="_blank" href="https://arxiv.org/pdf/1710.02322.pdf">pdf</a>]
              [<a target="_blank" href="https://github.com/dluvizon/pose-regression">code</a>]
              [<a target="_blank" href="data/cg2019.txt">bibtex</a>]
            </p>
          </article>

          <article class="8u 12u$(xsmall) work-item">
            <h3>2D/3D Pose Estimation and Action Recognition Using Multitask Deep Learning</h3>
            <a href="http://openaccess.thecvf.com/content_cvpr_2018/CameraReady/0131.pdf" target="_blank" class="image fit thumb"><img src="images/cvpr2018.svg" alt="" /></a>
            <p><b>Diogo C. Luvizon, David Picard, Hedi Tabia</b>. <i>The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</i>, 2018.</p>
            <p>
              [<a target="_blank" href="http://openaccess.thecvf.com/content_cvpr_2018/CameraReady/0131.pdf">pdf</a>]
              [<a target="_blank" href="http://openaccess.thecvf.com/content_cvpr_2018/Supplemental/0131-supp.pdf">supp</a>]
              [<a target="_blank" href="https://www.youtube.com/watch?v=MNEZACbFA4Y">demo</a>]
              [<a target="_blank" href="https://github.com/dluvizon/deephar">code</a>]
              [<a target="_blank" href="data/cvpr2018.txt">bibtex</a>]
            </p>
          </article>

          <article class="8u 12u$(xsmall) work-item">
            <h3>Learning features combination for human action recognition from skeleton sequences</h3>
            <a href="https://hal.archives-ouvertes.fr/hal-01515376/document" target="_blank" class="image fit thumb"><img src="images/prl2017.png" alt="" /></a>
            <p><b>Diogo Carbonera Luvizon, Hedi Tabia, David Picard</b>. <i>Pattern Recognition Letters</i>, 2017.</p>
            <p>
              [<a target="_blank" href="https://hal.archives-ouvertes.fr/hal-01515376/document">pdf</a>]
              [<a target="_blank" href="https://github.com/dluvizon/harskel">code</a>]
              [<a target="_blank" href="data/prl2017.txt">bibtex</a>]
              [<a target="_blank" href="https://www.sciencedirect.com/science/article/pii/S0167865517300326?via%3Dihub">elsevier</a>]
            </p>
          </article>

          <article class="8u 12u$(xsmall) work-item">
            <h3>A Video-Based System for Vehicle Speed Measurement in Urban Roadways</h3>
            <a href="http://www.dainf.ct.utfpr.edu.br/~rminetto/projects/vehicle-speed/" target="_blank" class="image fit thumb"><img src="images/its2016.jpg" alt="" /></a>
            <p><b>Diogo C. Luvizon, Bogdan T. Nassu, Rodrigo Minetto</b>. <i>The IEEE Transactions on Intelligent Transportation Systems (ITS)</i>, 2017.</p>
            <p>
              [<a target="_blank" href="http://www.dainf.ct.utfpr.edu.br/~rminetto/projects/vehicle-speed/Paper_ITS_final.pdf">pdf</a>]
              [<a target="_blank" href="http://www.dainf.ct.utfpr.edu.br/~rminetto/projects/vehicle-speed/OLD/gst-plugin_DETECTOR-MINETTO-2-g534ebc9.tar.bz2">code</a>]
              [<a target="_blank" href="http://www.youtube.com/watch?v=3IaKJuZN55k">demo</a>]
              [<a target="_blank" href="data/its2016.txt">bibtex</a>]
              [<a target="_blank" href="https://ieeexplore.ieee.org/document/7576700/">ieeexplore</a>]
            </p>
          </article>

          <article class="8u 12u$(xsmall) work-item">
            <h3>Vehicle speed estimation by license plate detection and tracking</h3>
            <a href="https://ieeexplore.ieee.org/document/6854869/" target="_blank" class="image fit thumb"><img src="images/icassp2014.png" alt="" /></a>
            <p><b>Diogo C. Luvizon, Bogdan T. Nassu, Rodrigo Minetto</b>. <i>The IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</i>, 2014.</p>
            <p>
              [<a target="_blank" href="data/icassp2014.txt">bibtex</a>]
              [<a target="_blank" href="https://ieeexplore.ieee.org/document/6854869/">ieeexplore</a>]
            </p>
          </article>

          <h3>Patents</h3>

          <p class="8u 12u$(xsmall) work-item justified">
            - <highlight>Granted!</highlight> <b>Diogo Carbonera Luvizon</b>; Henrique Fabricio Gagliardi; Otavio Augusto Bizetto Penatti. "Method for generating an adaptive multiplane image from a single high-resolution image", <b>US 11,704,778 B2</b>, 2023, Samsung.<br />
            - <b>Luvizon, Diogo Carbonera</b>; Pessurno De, Carvalho Gustavo Sutter; Bizetto Penatti, Otavio Augusto. "COMPUTER IMPLEMENTED METHOD AND SYSTEM FOR CLASSIFYING AN INPUT IMAGE FOR NEW VIEW SYNTHESIS IN A 3D VISUAL EFFECT, AND NON-TRANSITORY COMPUTER READABLE STORAGE MEDIUM", <b>US 2023/0196659 A1</b>, 2023, Samsung.<br />
            - <b>LUVIZON, DIOGO C.</b>; MINETTO, RODRIGO; NASSU, B. T. "Sistema para Medição de Velocidade Instantânea e Média de Veículos por Reconhecimento de Padrões em Imagens e Vídeos Digitais", INPI - Instituto Nacional da Propriedade Industrial, Registro No. <b>BR10201503191</b>, 2015 (Brazil, in Portuguese).
          </p>

          <h3>Awards and Prizes</h3>

          
          <p class="8u 12u$(xsmall) work-item justified">
            - <highlight>Best Paper Honorable Mention</highlight> on the Symposium on Vision, Modeling, and Visualization (GCPR-VMV), 2022, Konstanz, Germany.
            [<a target="_blank" href="https://handtracker.mpi-inf.mpg.de/projects/HandFlow/">Project Page</a>]<br />
            - <b>Best Presentation Award</b> in the annual ETIS Lab workshop, 2018, France.<br />
            - <highlight>1st Prize</highlight> on Workshop of Theses and Dissertations (WTD - Master), Conference on Graphics, Patterns and Images (SIBGRAPI), 2016, Brazil.
            Master's Thesis available <a target="_blank" href="http://repositorio.utfpr.edu.br/jspui/bitstream/1/1380/1/CT_PPGCA_M_Luvizon%2C%20Diogo%20Carbonera_2015.pdf">here</a>.<br />
            - <b>2nd Prize</b> on Concurso Latino-Americano de Dissertações de Mestrado (CLTM), Conferência Latino-Americana de Informática (CLEI), 2016, Chile.<br />
            - <b>Individual Grant</b> (90K) from the Brazilian National Council for Scientific and Technological Development (CNPq) for PhD abroad, 2015.
          </p>  

          <h3>Teaching - Master Sc. (at ENSEA, 2017-2018)</h3>
            <p>UEC-1-IMD Int. images et multimedia</p>
            <ul>
              <li>Action recognition from skeletons, VLAD, and LMNN: <a href="http://perso-etis.ensea.fr/luvizon/pluxml/Master_Interpretation_Images_PHD.pdf" target="_blank">slides</a></li>
              <li>Intro. to Neural Networks and Deep Learning: <a href="http://perso-etis.ensea.fr/luvizon/pluxml/NN_and_DeepLearning2.pdf" target="_blank">slides</a></li>
              <li>Intro. to Generative Adversarial Networks: <a href="http://perso-etis.ensea.fr/luvizon/pluxml/GANs.pdf" target="_blank">slides</a></li>
              <li>IA et Big Data: TP GANs 2018-2019 <a href="http://perso-etis.ensea.fr/luvizon/pluxml/tp_gans.pdf" target="_blank">link</a></li>
          </ul>

          <h3>Source Code </h3>
        
          <p class="8u 12u$(xsmall) work-item justified">
            The public source code related to my work is available on my
            <a href="https://github.com/dluvizon" target="_blank">GitHub</a>.<br/>
          </p>

        </div>
      </section>


      <!-- Contact -->
        <section id="contact">
          <h2>Contact</h2>
          <div class="row">
            <div class="6u$ 12u$(small)">
              <ul class="labeled-icons">
                <li>
                  <h3 class="icon fa-home"><span class="label">Address</span></h3>
                  Diogo Carbonera Luvizon<br />
                  Max-Planck-Institut für Informatik, Saarbrücken, Germany<br />
                  Visual Computing and Artificial Intelligence<br />
                  VIA Research Center
                </li>
                <!--<li>-->
                  <!--<h3 class="icon fa-mobile"><span class="label">Phone</span></h3>-->
                  <!--+33 01 30 73 62 92-->
                <!--</li>-->
                <li>
                  <h3 class="icon fa-envelope-o"><span class="label">Email</span></h3>
                  <a href="#contact">dluvizon [at] mpi-inf.mpg.de</a>
                </li>
                <li>
                  <h3 class="icon fa-language"><span class="label">Language</span></h3>
                  Fluente in <b>English</b>, <b>French</b>, and <b>Poruguese</b>; basic <b>German</b>
                </li>
              </ul>
            </div>
          </div>
        </section>

    </div>

		<!-- Footer -->
			<footer id="footer">
				<div class="inner">
					<ul class="icons">
						<li><a href="#contact" class="icon fa-envelope-o"><span class="label">Email</span></a></li>
						<li><a href="https://scholar.google.com/citations?user=VZ1Q5v4AAAAJ&hl=fr&oi=ao" class="icon fa-google"><span class="label">Scholar</span></a></li>
						<li><a href="https://github.com/dluvizon" target="_blank" class="icon fa-github"><span class="label">GitHub</span></a></li>
						<li><a href="https://twitter.com/DiogoLuvizon" target="_blank" class="icon fa-twitter"><span class="label">Twitter</span></a></li>
						<li><a href="https://www.linkedin.com/in/diogocl" target="_blank" class="icon fa-linkedin"><span class="label">LinkdIn</span></a></li>
            <li><a href="http://lattes.cnpq.br/9871965222373987" target="_blank" class="icon">Lattes<span class="label">Lattes</span></a></li>
					</ul>
					<ul class="copyright">
						<li>&copy; Copyright Diogo Carbonera Luvizon, 2024.</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
					</ul>
				</div>
			</footer>

		<!-- Scripts -->
    <script src="assets/js/jquery.min.js"></script>
    <script src="assets/js/jquery.poptrox.min.js"></script>
    <script src="assets/js/skel.min.js"></script>
    <script src="assets/js/util.js"></script>
    <!--[if lte IE 8]><script src="assets/js/ie/respond.min.js"></script><![endif]-->
    <script src="assets/js/main.js"></script>

    <!-- Grab Google CDN's jQuery. fall back to local if necessary -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script>window.jQuery || document.write("<script src='assets/js/libs/jquery-1.11.3.min.js'>\x3C/script>")</script>

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-121239782-1"></script>
    <script>
  window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

        gtag('config', 'UA-121239782-1');
    </script>

	</body>

</html>
